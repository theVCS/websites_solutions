{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 882,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pickle\r\n",
    "import joblib\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn as sn\r\n",
    "#from sklearn import datasets\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "import cv2\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "from scipy.stats import randint\r\n",
    "from scipy.stats import norm\r\n",
    "from openml import tasks, flows, runs, datasets, config\r\n",
    "import random\r\n",
    "\r\n",
    "task_id = 31\r\n",
    "task = tasks.get_task(task_id)\r\n",
    "dataset = datasets.get_dataset(task.dataset_id)\r\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\r\n",
    "    dataset_format=\"dataframe\", target=dataset.default_target_attribute\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "source": [
    "def fun1(val):\r\n",
    "    if val == '<0':\r\n",
    "        return \"checking_acc_less_than_0\"\r\n",
    "    elif val == '0<=X<200':\r\n",
    "        return \"checking_acc_bt_0_and_200\"\r\n",
    "    elif val == '>=200':\r\n",
    "        return \"checking_acc_greater_than_200\"\r\n",
    "    else:\r\n",
    "        return \"no_checking_acc\"\r\n",
    "\r\n",
    "\r\n",
    "def fun2(val):\r\n",
    "    if val == 'critical/other existing credit':\r\n",
    "        return \"critical_or_existing_credit_history\"\r\n",
    "    elif val == 'existing paid':\r\n",
    "        return \"existing_paid_credit_history\"\r\n",
    "    elif val == 'delayed previously':\r\n",
    "        return \"delayed_previously_credit_history\"\r\n",
    "    elif val == \"no credits/all paid\":\r\n",
    "        return \"no_credit_or_all_paid_credit_history\"\r\n",
    "    else:\r\n",
    "        return \"all_paid_credit_history\"\r\n",
    "\r\n",
    "\r\n",
    "def fun3(val):\r\n",
    "    if val == 'no known savings':\r\n",
    "        return \"no_saving_account\"\r\n",
    "    elif val == '<100':\r\n",
    "        return \"less_than_100_saving_account\"\r\n",
    "    elif val == '500<=X<1000':\r\n",
    "        return \"bt_500_and_1000_saving_account\"\r\n",
    "    elif val == \">=1000\":\r\n",
    "        return \"greater_than_1000_saving_account\"\r\n",
    "    else:\r\n",
    "        return \"bt_100_and_500_saving_account\"\r\n",
    "\r\n",
    "\r\n",
    "def fun4(val):\r\n",
    "    if val == '>=7':\r\n",
    "        return \"employed_more_than_7\"\r\n",
    "    elif val == '1<=X<4':\r\n",
    "        return \"employed_bt_1_and_4\"\r\n",
    "    elif val == '4<=X<7':\r\n",
    "        return \"employed_bt_4_and_7\"\r\n",
    "    elif val == \"unemployed\":\r\n",
    "        return \"not_employed\"\r\n",
    "    else:\r\n",
    "        return \"employed_less_than_1\"\r\n",
    "\r\n",
    "\r\n",
    "def train_data_clean(X, y):\r\n",
    "    # cleaning checking status\r\n",
    "    df = pd.concat([X, y], axis=\"columns\")\r\n",
    "\r\n",
    "    df.checking_status = df.checking_status.apply(lambda x: fun1(x))\r\n",
    "    dummies = pd.get_dummies(df.checking_status)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"checking_status\", \"no_checking_acc\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # cleaning credit history\r\n",
    "    df.credit_history = df.credit_history.apply(lambda df: fun2(df))\r\n",
    "    dummies = pd.get_dummies(df.credit_history)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop(\r\n",
    "        [\"credit_history\", \"no_credit_or_all_paid_credit_history\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # purpose\r\n",
    "    dummies = pd.get_dummies(df.purpose)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"purpose\", \"other\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # savings status\r\n",
    "    df.savings_status = df.savings_status.apply(lambda x: fun3(x))\r\n",
    "    dummies = pd.get_dummies(df.savings_status)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"savings_status\", \"no_saving_account\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # employment\r\n",
    "    df.employment = df.employment.apply(lambda x: fun4(x))\r\n",
    "    dummies = pd.get_dummies(df.employment)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"employment\", \"not_employed\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # personal_status\r\n",
    "    dummies = pd.get_dummies(df.personal_status)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"personal_status\", \"female div/dep/mar\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # other_parties\r\n",
    "    dummies = pd.get_dummies(df.other_parties)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"other_parties\", \"none\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # property_magnitude\r\n",
    "    dummies = pd.get_dummies(df.property_magnitude)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"property_magnitude\", \"car\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # other_payment_plans\r\n",
    "    dummies = pd.get_dummies(df.other_payment_plans)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"other_payment_plans\", \"none\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # housing\r\n",
    "    dummies = pd.get_dummies(df.housing)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"housing\", \"for free\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # job\r\n",
    "    dummies = pd.get_dummies(df.job)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"job\", \"unemp/unskilled non res\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # own_telephone\r\n",
    "    df.own_telephone = df.own_telephone.apply(\r\n",
    "        lambda x: \"have_telephone\" if x == \"yes\" else \"no_telephone\")\r\n",
    "    dummies = pd.get_dummies(df.own_telephone)\r\n",
    "    df = pd.concat([df, dummies], axis=\"columns\")\r\n",
    "    df = df.drop([\"own_telephone\", \"no_telephone\"], axis=\"columns\")\r\n",
    "\r\n",
    "    # foreign_worker\r\n",
    "    df.foreign_worker = df.foreign_worker.apply(\r\n",
    "        lambda x: 1 if x == \"yes\" else 0)\r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "source": [
    "X = train_data_clean(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "source": [
    "lst = [\"credit_amount\", \"duration\"]\r\n",
    "\r\n",
    "for col in lst:\r\n",
    "       mean = X[col].mean()\r\n",
    "       std = X[col].std()\r\n",
    "       X = X[(X[col] > mean - std) & (X[col] < mean + std)]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "source": [
    "y = X[\"class\"]\r\n",
    "X = X.drop([\"class\"], axis=\"columns\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "source": [
    "# model_params = {\r\n",
    "#     'random_forest': {\r\n",
    "#         'model': RandomForestClassifier(),\r\n",
    "#         'params': {\r\n",
    "#                 'n_estimators': randint(10,100),\r\n",
    "#                 \"max_features\": randint(1,64),\r\n",
    "#                 'max_depth': [randint(5,50), None],\r\n",
    "#                 \"min_samples_split\": randint(2,11),\r\n",
    "#                 \"min_samples_leaf\": randint(1,11),\r\n",
    "#                 \"criterion\":['gini','entropy'],\r\n",
    "#                 \"bootstrap\": [True, False],\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'svm': {\r\n",
    "#         'model': svm.SVC(gamma='auto', C=1),\r\n",
    "#         'params': {\r\n",
    "#             'C': [0.1,1, 10, 100],\r\n",
    "#             # 'kernel': ['rbf', 'poly', 'sigmoid'],\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'logistic_regression': {\r\n",
    "#         'model': LogisticRegression(),\r\n",
    "#         'params': {\r\n",
    "#             'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\r\n",
    "#             'C' : np.logspace(-4, 4, 20),\r\n",
    "#             'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\r\n",
    "#             'max_iter' : [100, 1000,2500, 5000],\r\n",
    "\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'decision_tree': {\r\n",
    "#         'model': DecisionTreeClassifier(),\r\n",
    "#         'params': {\r\n",
    "#             \"max_depth\": [2, 3, 4, 5, 6, 7, 8 , 9, None],\r\n",
    "#             \"max_features\": [2, 3, 4, 5, 6, 7, 8 , 9],\r\n",
    "#             \"min_samples_leaf\": [2, 3, 4, 5, 6, 7, 8 , 9, None],\r\n",
    "#             \"criterion\": [\"gini\", \"entropy\"],\r\n",
    "#             \"splitter\": [\"best\", \"random\"]\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'GaussianNB': {\r\n",
    "#         'model': GaussianNB(),\r\n",
    "#         'params': {\r\n",
    "#             'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'MultinomialNB': {\r\n",
    "#         'model': MultinomialNB(),\r\n",
    "#         'params': {\r\n",
    "#             'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "#     'BernoulliNB': {\r\n",
    "#         'model': BernoulliNB(),\r\n",
    "#         'params': {\r\n",
    "#             'alpha':np.linspace(0.1,1,10)\r\n",
    "#         }\r\n",
    "#     },\r\n",
    "# }\r\n",
    "\r\n",
    "# score = []\r\n",
    "\r\n",
    "# for model_name, mp in model_params.items():\r\n",
    "#     clf =  RandomizedSearchCV(mp['model'], mp['params'], n_iter=100, cv=3,scoring='accuracy')\r\n",
    "#     clf.fit(X, y)\r\n",
    "#     score.append({\r\n",
    "#         'model': model_name,\r\n",
    "#         'best_score': clf.best_score_,\r\n",
    "#         'best_params': clf.best_params_\r\n",
    "#     })\r\n",
    "    \r\n",
    "# df = pd.DataFrame(score,columns=['model','best_score','best_params'])\r\n",
    "# df\r\n",
    "# df.to_csv(\"data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "source": [
    "model = LogisticRegression(solver= 'liblinear', penalty='l2', max_iter=5000, C= 4.2813323987193)\r\n",
    "model.fit(x_train, y_train)\r\n",
    "model.score(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.772020725388601"
      ]
     },
     "metadata": {},
     "execution_count": 903
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<code object get_dataset at 0x000001E9CC6CFEA0, file \"D:\\program files\\python\\lib\\site-packages\\openml\\tasks\\task.py\", line 118>"
      ]
     },
     "metadata": {},
     "execution_count": 902
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "source": [
    "run.data_content\r\n",
    "run = runs.run_model_on_task(model, task)\r\n",
    "# run.publish()\r\n",
    "# print(f'View the run online: {run.openml_url}')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_13552/1255235993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mruns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model_on_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# run.publish()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(f'View the run online: {run.openml_url}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "fe891c9e592bf780402d820d64490eaf7700f53018646db208523a8585c3ebd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}